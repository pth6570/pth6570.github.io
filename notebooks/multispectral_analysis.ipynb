{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62e02a7624d7768be1e0d7717d4b33d6",
     "grade": false,
     "grade_id": "ans-imports",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import earthpy as et\n",
    "import earthpy.earthexplorer as etee\n",
    "import geopandas as gpd \n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import rioxarray.merge as rxrmerge\n",
    "import shutil\n",
    "from bokeh.models import HoverTool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data Directories for Project\n",
    "data_dir = os.path.join(et.io.HOME, et.io.DATA_NAME)\n",
    "dc_dir = os.path.join(data_dir, 'dc-neighborhoods')\n",
    "ndvi_dir = os.path.join(data_dir, 'dc-green-space', 'processed')\n",
    "\n",
    "# Check is file directory exists and if not, create it\n",
    "for file_dir in [dc_dir, ndvi_dir]:\n",
    "    if not os.path.exists(file_dir):\n",
    "        os.makedirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save url for DC Neighborhood boundaries\n",
    "dc_url = (\"https://maps2.dcgis.dc.gov/dcgis/rest/services/DCGIS_DATA/\"\n",
    "           \"Administrative_Other_Boundaries_WebMercator/MapServer/17/\"\n",
    "           \"query?outFields=*&where=1%3D1&f=geojson\")\n",
    "\n",
    "# Get DC Neighborhood Boundaries as a Shapefiles\n",
    "dc_nbd_gdf = gpd.read_file(dc_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ea109f4d72fe9c96476d2989bc797d3",
     "grade": false,
     "grade_id": "ans-download-neighborhoods",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>WEB_URL</th>\n",
       "      <th>NBH_NAMES</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>GLOBALID</th>\n",
       "      <th>CREATOR</th>\n",
       "      <th>CREATED</th>\n",
       "      <th>EDITOR</th>\n",
       "      <th>EDITED</th>\n",
       "      <th>SHAPE.AREA</th>\n",
       "      <th>SHAPE.LEN</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cluster 9</th>\n",
       "      <td>41</td>\n",
       "      <td>http://planning.dc.gov/</td>\n",
       "      <td>Southwest Employment Area, Southwest/Waterfron...</td>\n",
       "      <td>Original</td>\n",
       "      <td>{0D85A9B0-AAE1-4EE0-A311-793BC87ED3C5}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-77.02192 38.88757, -77.02742 38.887...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 31</th>\n",
       "      <td>33</td>\n",
       "      <td>http://planning.dc.gov/</td>\n",
       "      <td>Deanwood, Burrville, Grant Park, Lincoln Heigh...</td>\n",
       "      <td>Original</td>\n",
       "      <td>{84876282-0AFE-4553-8F28-958497FC1A4C}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-76.91322 38.88976, -76.91234 38.890...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            OBJECTID                  WEB_URL  \\\n",
       "NAME                                            \n",
       "Cluster 9         41  http://planning.dc.gov/   \n",
       "Cluster 31        33  http://planning.dc.gov/   \n",
       "\n",
       "                                                    NBH_NAMES      TYPE  \\\n",
       "NAME                                                                      \n",
       "Cluster 9   Southwest Employment Area, Southwest/Waterfron...  Original   \n",
       "Cluster 31  Deanwood, Burrville, Grant Park, Lincoln Heigh...  Original   \n",
       "\n",
       "                                          GLOBALID CREATOR CREATED EDITOR  \\\n",
       "NAME                                                                        \n",
       "Cluster 9   {0D85A9B0-AAE1-4EE0-A311-793BC87ED3C5}    None    None   None   \n",
       "Cluster 31  {84876282-0AFE-4553-8F28-958497FC1A4C}    None    None   None   \n",
       "\n",
       "           EDITED  SHAPE.AREA  SHAPE.LEN  \\\n",
       "NAME                                       \n",
       "Cluster 9    None           0          0   \n",
       "Cluster 31   None           0          0   \n",
       "\n",
       "                                                     geometry  \n",
       "NAME                                                           \n",
       "Cluster 9   POLYGON ((-77.02192 38.88757, -77.02742 38.887...  \n",
       "Cluster 31  POLYGON ((-76.91322 38.88976, -76.91234 38.890...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define path to DC Neighborhood Data\n",
    "dc_path = os.path.join(dc_dir, 'dc-neighborhood.geojson')\n",
    "\n",
    "\n",
    "\n",
    "# If the data does not already exist, save data to directory\n",
    "if not os.path.exists(dc_path):\n",
    "    # Save url for Chicago Neighborhood boundaries\n",
    "    dc_url = (\"https://maps2.dcgis.dc.gov/dcgis/rest/services/DCGIS_DATA/\"\n",
    "            \"Administrative_Other_Boundaries_WebMercator/MapServer/17/\"\n",
    "            \"query?outFields=*&where=1%3D1&f=geojson\"\n",
    "    )\n",
    "    # Save Chicago neighborhood data to a file\n",
    "    gpd.read_file(dc_url).to_file(dc_path)\n",
    "\n",
    "# Create Geodatabase of Chicago Neighborhood Data\n",
    "dc_gdf = gpd.read_file(dc_path).set_index(\"NAME\")\n",
    "\n",
    "# Select Humboldt Park and Lincoln Park Data\n",
    "neigh_gdf = (\n",
    "    dc_gdf\n",
    "    .loc[[\"Cluster 9\", \"Cluster 31\"]]\n",
    ")\n",
    "\n",
    "neigh_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4596c75f3a5704868766ee0db3560337",
     "grade": false,
     "grade_id": "step-3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## STEP 3: Download and process raster data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e2a1f5a358962445e8de4dcb9ed5261",
     "grade": false,
     "grade_id": "task-download",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "You should have three loops from last week. Convert the operations from each loop into a **function**, starting with the following sample code:\n",
    "\n",
    "```python\n",
    "def download_neighborhood_data(name, geometry, start, end)\n",
    "    \"\"\"\n",
    "    Download NAIP raster for a given geometry, start date, and end date\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    name : str\n",
    "      The name used to label the download\n",
    "    geometry : shapely.POLYGON\n",
    "      The geometry to derive the download extent from. \n",
    "      Must have a `.bounds` attribute.\n",
    "    start : str\n",
    "      The start date as 'YYYY-MM-DD'\n",
    "    end : str\n",
    "      The end date as 'YYYY-MM-DD'\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    downloader : earthpy.earthexplorer.EarthExplorerDownloader\n",
    "      Object with information about the download, including the data directory.\n",
    "    \"\"\"\n",
    "    <Put your code here>\n",
    "    return downloader\n",
    "\n",
    "for neighborhood_name, details in neigh_gdf.interrows():\n",
    "    download_neighborhood_data(neighborhood_name, details.geometry)\n",
    "\n",
    "```\n",
    "One important step of writing function is identifying the **Parameters** and **Returns**. In this case, I have done this for you; for later functions you will need to do this yourself. One way to identify the Parameters is to identify each object or variable used in the code (note that this does not usually include imported classes and functions). \n",
    "\n",
    "I am also supplying you with a **docstring** that explains the Parameters and Returns, and specifies their types. Update the docstring if you decide to do something different for your function. When writing docstrings, please follow the [numpy docstring styleguide](https://numpydoc.readthedocs.io/en/latest/format.html#sections)\n",
    "\n",
    "YOUR TASK:\n",
    "\n",
    "1. Replace `<Put your code here>` with the download code from last week\n",
    "2. Open up your summary statistics file, if it exists.\n",
    "3. Add a **conditional** to your code so that it will skip this download if the summary statistics **already exist** in your summary statistics file!\n",
    "   \n",
    "    > HINT: I did this using the `pass` statement, which moves on to the next iteration of the loop. This way you can test if the statistics **do** exist in the file, rather than whether they **do not**. However, there are lots of ways to do this -- do what makes sense to you!\n",
    "    \n",
    "4. Test that the code still works for the two-neighborhood `GeoDataFrame`. You should also check that the caching is working (although you may need to wait until you have saved some statistics to do this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7be14fe3d75462ced1803cf9a1a52cf2",
     "grade": false,
     "grade_id": "ans-download",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI Statistics File does not exist...\n"
     ]
    }
   ],
   "source": [
    "def download_neighborhood_data(name, geometry, start, end):\n",
    "    \"\"\"\n",
    "    Download NAIP raster for a given geometry, start date, and end date\n",
    "\n",
    "    Downloads data from the National Agricultural Imagery Program (NAIP)\n",
    "    given a spatial and temporal extent.\n",
    "    <citation>\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    name : str\n",
    "      The name used to label the download\n",
    "    geometry : shapely.POLYGON\n",
    "      The geometry to derive the download extent from. \n",
    "      Must have a `.bounds` attribute.\n",
    "    start : str\n",
    "      The start date as 'YYYY-MM-DD'\n",
    "    end : str\n",
    "      The end date as 'YYYY-MM-DD'\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    downloader : earthpy.earthexplorer.EarthExplorerDownloader\n",
    "      Object with information about the download, including the data directory.\n",
    "    \"\"\"\n",
    "    print(f'Neighborhood Name: {name}')\n",
    "    # Create bounding box\n",
    "    bbox = etee.BBox(*geometry.bounds)\n",
    "    # Create downloader\n",
    "    naip_downloader = etee.EarthExplorerDownloader(\n",
    "        dataset=\"NAIP\", \n",
    "        label=name.lower().replace(\" \", \"-\"),\n",
    "        bbox=bbox,\n",
    "        start=start,\n",
    "        end=end,\n",
    "        store_credential=False)\n",
    "    # Request and download data\n",
    "    naip_downloader.submit_download_request()\n",
    "    naip_downloader.download(override=False)\n",
    "    return naip_downloader\n",
    "\n",
    "ndvi_stats_path = os.path.join(ndvi_dir, 'neighborhood-ndvi-stats.csv')\n",
    "if os.path.exists(ndvi_stats_path):\n",
    "  print('Reading in NDVI Statistics File...')\n",
    "  ndvi_stats_df = pd.read_csv(ndvi_stats_path, index_col=\"neighborhood\")\n",
    "else:\n",
    "  print('NDVI Statistics File does not exist...')\n",
    "  ndvi_stats_df = pd.DataFrame()\n",
    "\n",
    "# # Run to test\n",
    "# for neighborhood_name, details in neigh_gdf.iterrows():\n",
    "#     if neighborhood_name in ndvi_stats_df.index:\n",
    "#       print(\"Neighborhood stats have already been calculated. Skipping\")\n",
    "#       continue\n",
    "    \n",
    "#     downloader = download_neighborhood_data(\n",
    "#        neighborhood_name, details.geometry, '2021-01-01', '2021-12-31')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "870b3a9b4907656fbc64d5d23e37b538",
     "grade": false,
     "grade_id": "task-load-merge",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "YOUR TASK: \n",
    "\n",
    "1. Write a function for the loop that loads and merges the arrays.\n",
    "2. Document your function with a docstring\n",
    "3. Check that your function works for the Lincoln Park neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92ce6ede0b1456b0cc52aead0b3de308",
     "grade": false,
     "grade_id": "ans-merge",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_and_merge_arrays(name):\n",
    "    \"\"\"\n",
    "    Load in and merge downloaded arrays\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    name : str\n",
    "        The name used to label the download\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    merge_da : rxr.DataArray\n",
    "        Data array with merged data.\n",
    "    \"\"\"\n",
    "    # Merge data for each neighborhood\n",
    "    print(f'\\nNeighborhood Name: {name}')\n",
    "    data_path = os.path.join(\n",
    "        et.io.HOME, et.io.DATA_NAME,\n",
    "        name.lower().replace(' ', '-'))\n",
    "    # Define paths to tif data\n",
    "    tif_paths = glob(os.path.join(data_path, '*.tif'))\n",
    "    # Load tifs\n",
    "    das = [rxr.open_rasterio(tp, masked=True) for tp in tif_paths]\n",
    "    # Merge arrays\n",
    "    merged_da = rxrmerge.merge_arrays(das)\n",
    "    return merged_da\n",
    "\n",
    "# # Run to test\n",
    "# merged_da = load_and_merge_arrays('Cluster 9')\n",
    "# merged_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "705ce678b94060c99feb3967a40ebfb0",
     "grade": false,
     "grade_id": "task-summarize",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "YOUR TASK:\n",
    "\n",
    "1. Write a function that computes the NDVI summary statistics and adds them to the statistics file (if the statistics are not already present)\n",
    "    > HINT: use `mode='a'` to *append* a line to the file instead of writing over existing content\n",
    "    \n",
    "2. Document your function with a docstring\n",
    "3. Check that your function works for the Lincoln Park Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96b502b32233419baede0d41d49b1762",
     "grade": false,
     "grade_id": "ans-ndvi",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Function to compute NDVI summary statistics\n",
    "def calculate_ndvi_stats(gdf, da, stats_path, override=False):\n",
    "    \"\"\"\n",
    "    Calculate NDVI summary statistics and save to statistics file\n",
    "    \n",
    "    Uses downloaded National Agricultural Imagery Program (NAIP) data.\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    gdf : [gpd.GeoDataFrame]\n",
    "        Single row with the neighborhood name and boundary\n",
    "    da : rxr.DataArray\n",
    "        Multispectral raster data from NAIP\n",
    "    stats_path : pathlike\n",
    "        The path to the statistics file to save results\n",
    "    \"\"\"\n",
    "    name = str(gdf.index[0])\n",
    "    print(f'\\nNeighborhood Name: {name}')\n",
    "\n",
    "    file_is_empty = True\n",
    "    if os.path.exists(stats_path):\n",
    "        print('Stats file exists.')\n",
    "        stats_df = pd.read_csv(stats_path)\n",
    "        with open(stats_path, 'r') as stats_file:\n",
    "            file_is_empty = len(stats_file.read())==0\n",
    "            print(f'Stats file is empty? {file_is_empty}')\n",
    "            \n",
    "            if not file_is_empty:\n",
    "                if name in list(stats_df.neighborhood) and (not override):\n",
    "                    print('Stats already calculated. Skipping...')\n",
    "                    return\n",
    "\n",
    "\n",
    "    # Create gdf for neighborhood\n",
    "    reprojected_gdf = gdf.to_crs(da.rio.crs)\n",
    "    # Crop NAIP data array to the neighborhood\n",
    "    naip_crop_da = (\n",
    "        da.rio.clip_box(*reprojected_gdf.total_bounds)\n",
    "        )\n",
    "    naip_da = (\n",
    "        naip_crop_da.rio.clip(reprojected_gdf.geometry)\n",
    "    )\n",
    "    \n",
    "    mode = 'w' if file_is_empty else 'a'\n",
    "    # Calculate NDVI\n",
    "    ndvi_da = (da.sel(band=4) - da.sel(band=1)) / (\n",
    "        da.sel(band=4) + da.sel(band=1)\n",
    "    )\n",
    "    print('Writing stats to file')\n",
    "    file_is_empty = not os.path.exists(stats_path)\n",
    "    # Calculate summary statistics\n",
    "    pd.DataFrame(dict(\n",
    "          neighborhood=[name],\n",
    "          ndvi_25pctl=[np.nanpercentile(ndvi_da, 25)],\n",
    "          ndvi_mean=[float(ndvi_da.mean())]\n",
    "          )).to_csv(stats_path, mode=mode, header=file_is_empty, index=False)\n",
    "\n",
    "# Run to test\n",
    "# calculate_ndvi_stats(dc_gdf.loc[['Lincoln Park']], merged_da, ndvi_stats_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f5cc87a63ce81d58b2c8742cdeab0a6",
     "grade": false,
     "grade_id": "task-loop",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Putting in all together... YOUR TASK:\n",
    "\n",
    "1. Create a loop. Start off with just the two neighborhood `GeoDataFrame`.\n",
    "2. Run each of your functions in the loop, checking that they work. **MAKE SURE YOU INCLUDE CACHING CODE!**\n",
    "3. Write a line of code at the end of your loop to **delete the raster data files** once you have saved the statistics you want, checking that it works. Use the `shutil.rmtree()` function.\n",
    "4. Replace the two neighborhood `GeoDataFrame` with the full Chicago `GeoDataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a65a37500bd48e50dd4207d04090d3d",
     "grade": false,
     "grade_id": "ans-loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI statistics file does not exist...\n",
      "Neighborhood Name: Cluster 31\n",
      "Login Successful.\n",
      "Searching datasets...\n",
      "Using dataset alias: naip\n",
      "Searching scenes...\n",
      "Found 2 scenes\n",
      "2 products found.\n",
      "Downloads staging...\n",
      "/home/jovyan/earth-analytics/data/cluster-31/M_3807601_SW_18_060_20210617.zip\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/pth6570.github.io/notebooks/multispectral_analysis.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bjubilant-funicular-jj596r97xr7r35w7g/workspaces/pth6570.github.io/notebooks/multispectral_analysis.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNeighborhood stats have already been calculated. Skipping\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bjubilant-funicular-jj596r97xr7r35w7g/workspaces/pth6570.github.io/notebooks/multispectral_analysis.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bjubilant-funicular-jj596r97xr7r35w7g/workspaces/pth6570.github.io/notebooks/multispectral_analysis.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m downloader \u001b[39m=\u001b[39m download_neighborhood_data(\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bjubilant-funicular-jj596r97xr7r35w7g/workspaces/pth6570.github.io/notebooks/multispectral_analysis.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     neighborhood_name, details\u001b[39m.\u001b[39;49mgeometry, \u001b[39m'\u001b[39;49m\u001b[39m2021-01-01\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m2021-12-31\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bjubilant-funicular-jj596r97xr7r35w7g/workspaces/pth6570.github.io/notebooks/multispectral_analysis.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m merged_da \u001b[39m=\u001b[39m load_and_merge_arrays(neighborhood_name)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bjubilant-funicular-jj596r97xr7r35w7g/workspaces/pth6570.github.io/notebooks/multispectral_analysis.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m calculate_ndvi_stats(\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bjubilant-funicular-jj596r97xr7r35w7g/workspaces/pth6570.github.io/notebooks/multispectral_analysis.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     dc_gdf\u001b[39m.\u001b[39mloc[[neighborhood_name]], merged_da, ndvi_stats_path)\n",
      "\u001b[1;32m/workspaces/pth6570.github.io/notebooks/multispectral_analysis.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bjubilant-funicular-jj596r97xr7r35w7g/workspaces/pth6570.github.io/notebooks/multispectral_analysis.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Request and download data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bjubilant-funicular-jj596r97xr7r35w7g/workspaces/pth6570.github.io/notebooks/multispectral_analysis.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m naip_downloader\u001b[39m.\u001b[39msubmit_download_request()\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bjubilant-funicular-jj596r97xr7r35w7g/workspaces/pth6570.github.io/notebooks/multispectral_analysis.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m naip_downloader\u001b[39m.\u001b[39;49mdownload(override\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bjubilant-funicular-jj596r97xr7r35w7g/workspaces/pth6570.github.io/notebooks/multispectral_analysis.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mreturn\u001b[39;00m naip_downloader\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/earthpy/earthexplorer.py:290\u001b[0m, in \u001b[0;36mEarthExplorerDownloader.download\u001b[0;34m(self, wait, timeout, override)\u001b[0m\n\u001b[1;32m    287\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mdownloadId\u001b[39m\u001b[39m'\u001b[39m: download[\u001b[39m'\u001b[39m\u001b[39mdownloadId\u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[1;32m    288\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost(\u001b[39m'\u001b[39m\u001b[39mdownload-remove\u001b[39m\u001b[39m'\u001b[39m, params)\n\u001b[0;32m--> 290\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muncompress(dld_path)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/earthpy/earthexplorer.py:299\u001b[0m, in \u001b[0;36mEarthExplorerDownloader.uncompress\u001b[0;34m(self, download_path)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mext\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mzip\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    298\u001b[0m     \u001b[39mwith\u001b[39;00m zipfile\u001b[39m.\u001b[39mZipFile(download_path, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m dld_zipfile:\n\u001b[0;32m--> 299\u001b[0m         dld_zipfile\u001b[39m.\u001b[39;49mextractall(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_dir)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1647\u001b[0m, in \u001b[0;36mZipFile.extractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1644\u001b[0m     path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(path)\n\u001b[1;32m   1646\u001b[0m \u001b[39mfor\u001b[39;00m zipinfo \u001b[39min\u001b[39;00m members:\n\u001b[0;32m-> 1647\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_member(zipinfo, path, pwd)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1702\u001b[0m, in \u001b[0;36mZipFile._extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1698\u001b[0m     \u001b[39mreturn\u001b[39;00m targetpath\n\u001b[1;32m   1700\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopen(member, pwd\u001b[39m=\u001b[39mpwd) \u001b[39mas\u001b[39;00m source, \\\n\u001b[1;32m   1701\u001b[0m      \u001b[39mopen\u001b[39m(targetpath, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m target:\n\u001b[0;32m-> 1702\u001b[0m     shutil\u001b[39m.\u001b[39;49mcopyfileobj(source, target)\n\u001b[1;32m   1704\u001b[0m \u001b[39mreturn\u001b[39;00m targetpath\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:195\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    193\u001b[0m fdst_write \u001b[39m=\u001b[39m fdst\u001b[39m.\u001b[39mwrite\n\u001b[1;32m    194\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 195\u001b[0m     buf \u001b[39m=\u001b[39m fsrc_read(length)\n\u001b[1;32m    196\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m buf:\n\u001b[1;32m    197\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:927\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    926\u001b[0m \u001b[39mwhile\u001b[39;00m n \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof:\n\u001b[0;32m--> 927\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read1(n)\n\u001b[1;32m    928\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(data):\n\u001b[1;32m    929\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_readbuffer \u001b[39m=\u001b[39m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:995\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    993\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail\n\u001b[1;32m    994\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m>\u001b[39m \u001b[39mlen\u001b[39m(data):\n\u001b[0;32m--> 995\u001b[0m         data \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read2(n \u001b[39m-\u001b[39;49m \u001b[39mlen\u001b[39;49m(data))\n\u001b[1;32m    996\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    997\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read2(n)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1027\u001b[0m, in \u001b[0;36mZipExtFile._read2\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1024\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(n, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMIN_READ_SIZE)\n\u001b[1;32m   1025\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compress_left)\n\u001b[0;32m-> 1027\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fileobj\u001b[39m.\u001b[39;49mread(n)\n\u001b[1;32m   1028\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compress_left \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data)\n\u001b[1;32m   1029\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:747\u001b[0m, in \u001b[0;36m_SharedFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt read from the ZIP file while there \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    744\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis an open writing handle on it. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    745\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mClose the writing handle before trying to read.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    746\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file\u001b[39m.\u001b[39mseek(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pos)\n\u001b[0;32m--> 747\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_file\u001b[39m.\u001b[39;49mread(n)\n\u001b[1;32m    748\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file\u001b[39m.\u001b[39mtell()\n\u001b[1;32m    749\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Redefine NDVI stats path\n",
    "ndvi_stats_path = os.path.join(ndvi_dir, 'neighborhood-ndvi-stats.csv')\n",
    "\n",
    "# Loop through all Chicago neighborhoods to download data, merge data,\n",
    "# and calculate NDVI statistics using functions\n",
    "for neighborhood_name, details in dc_gdf.iterrows():\n",
    "    if not os.path.exists(ndvi_stats_path):\n",
    "        print('NDVI statistics file does not exist...')\n",
    "        ndvi_stats_df = pd.DataFrame()\n",
    "    else:\n",
    "        ndvi_stats_df = pd.read_csv(ndvi_stats_path, index_col='neighborhood')\n",
    "        \n",
    "    if neighborhood_name in ndvi_stats_df.index:\n",
    "      print(\"Neighborhood stats have already been calculated. Skipping\")\n",
    "      continue\n",
    "        \n",
    "    downloader = download_neighborhood_data(\n",
    "        neighborhood_name, details.geometry, '2021-01-01', '2021-12-31')\n",
    "    merged_da = load_and_merge_arrays(neighborhood_name)\n",
    "    calculate_ndvi_stats(\n",
    "        dc_gdf.loc[[neighborhood_name]], merged_da, ndvi_stats_path)\n",
    "    \n",
    "    shutil.rmtree(downloader.data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ndvi_summary_stats.csv'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndvi_stats_path = os.path.join(ndvi_dir, 'neighborhood-ndvi-stats.csv')\n",
    "\n",
    "shutil.copyfile(ndvi_stats_path, \"ndvi_summary_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2faa5678764519b1c1834cc10c0e8e0",
     "grade": false,
     "grade_id": "cell-d424f92bd00373c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## STEP 4: Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "edb0231452a46a9ed12835cb86480997",
     "grade": false,
     "grade_id": "task-plot",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "YOUR TASK:\n",
    "1. Join your `GeoDataFrame` of Chicago neighborhoods with your NDVI statistics `DataFrame`\n",
    "2. Create a Chloropleth plot using one of the statistics for the color scale\n",
    "3. Write a plot headline and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in NDVI Summary Statistics\n",
    "# ndvi_stats_df = pd.read_csv(ndvi_stats_path, index_col=\"neighborhood\")\n",
    "\n",
    "# # Create copy of Neighborhood name for use in hover tool\n",
    "# joined_chi_df = chi_gdf.join(ndvi_stats_df, how=\"left\")\n",
    "# joined_chi_df['name'] = joined_chi_df.index\n",
    "\n",
    "# # Define hover tool for Choropleth\n",
    "# tooltips = [\n",
    "#     ('Neighborhood', '@name'),\n",
    "#     ('NDVI', '@ndvi_mean')\n",
    "# ]\n",
    "# hover = HoverTool(tooltips=tooltips)\n",
    "\n",
    "# # Create Choropleth of NDVI Statistics\n",
    "# choropleth = gv.tile_sources.CartoLight * gv.Polygons(\n",
    "#     joined_chi_df,\n",
    "#     vdims=['ndvi_mean', 'name']\n",
    "# ).opts(cmap=\"RdYlGn\",\n",
    "#        title=\"NDVI in Chicago Neighborhoods\",\n",
    "#        xaxis=None,\n",
    "#        yaxis=None,\n",
    "#        colorbar=True, \n",
    "#        colorbar_position=\"right\",\n",
    "#        tools=[hover])\n",
    "\n",
    "# # Save Chloropleth to HTML\n",
    "# hv.save(choropleth, 'choropleth.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDVI in Chicago Neighborhoods\n",
    "* NDVI tends to be lower closer to the lake. \n",
    "* Areas further from the lake tend to have higher NDVI.\n",
    "* In general, NDVI tends to be low (under zero) in Chicago."
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "249.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
