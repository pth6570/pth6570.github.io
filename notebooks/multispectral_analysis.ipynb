{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62e02a7624d7768be1e0d7717d4b33d6",
     "grade": false,
     "grade_id": "ans-imports",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import earthpy as et\n",
    "import earthpy.earthexplorer as etee\n",
    "import geopandas as gpd \n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import rioxarray.merge as rxrmerge\n",
    "import shutil\n",
    "from bokeh.models import HoverTool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data Directories for Project\n",
    "data_dir = os.path.join(et.io.HOME, et.io.DATA_NAME)\n",
    "dc_dir = os.path.join(data_dir, 'dc-neighborhoods')\n",
    "ndvi_dir = os.path.join(data_dir, 'dc-green-space', 'processed')\n",
    "\n",
    "# Check is file directory exists and if not, create it\n",
    "for file_dir in [dc_dir, ndvi_dir]:\n",
    "    if not os.path.exists(file_dir):\n",
    "        os.makedirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save url for DC Neighborhood boundaries\n",
    "dc_url = (\"https://maps2.dcgis.dc.gov/dcgis/rest/services/DCGIS_DATA/\"\n",
    "           \"Administrative_Other_Boundaries_WebMercator/MapServer/17/\"\n",
    "           \"query?outFields=*&where=1%3D1&f=geojson\")\n",
    "\n",
    "# Get DC Neighborhood Boundaries as a Shapefiles\n",
    "dc_nbd_gdf = gpd.read_file(dc_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ea109f4d72fe9c96476d2989bc797d3",
     "grade": false,
     "grade_id": "ans-download-neighborhoods",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>WEB_URL</th>\n",
       "      <th>NBH_NAMES</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>GLOBALID</th>\n",
       "      <th>CREATOR</th>\n",
       "      <th>CREATED</th>\n",
       "      <th>EDITOR</th>\n",
       "      <th>EDITED</th>\n",
       "      <th>SHAPE.AREA</th>\n",
       "      <th>SHAPE.LEN</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cluster 9</th>\n",
       "      <td>41</td>\n",
       "      <td>http://planning.dc.gov/</td>\n",
       "      <td>Southwest Employment Area, Southwest/Waterfron...</td>\n",
       "      <td>Original</td>\n",
       "      <td>{0D85A9B0-AAE1-4EE0-A311-793BC87ED3C5}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-77.02192 38.88757, -77.02742 38.887...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster 31</th>\n",
       "      <td>33</td>\n",
       "      <td>http://planning.dc.gov/</td>\n",
       "      <td>Deanwood, Burrville, Grant Park, Lincoln Heigh...</td>\n",
       "      <td>Original</td>\n",
       "      <td>{84876282-0AFE-4553-8F28-958497FC1A4C}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-76.91322 38.88976, -76.91234 38.890...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            OBJECTID                  WEB_URL  \\\n",
       "NAME                                            \n",
       "Cluster 9         41  http://planning.dc.gov/   \n",
       "Cluster 31        33  http://planning.dc.gov/   \n",
       "\n",
       "                                                    NBH_NAMES      TYPE  \\\n",
       "NAME                                                                      \n",
       "Cluster 9   Southwest Employment Area, Southwest/Waterfron...  Original   \n",
       "Cluster 31  Deanwood, Burrville, Grant Park, Lincoln Heigh...  Original   \n",
       "\n",
       "                                          GLOBALID CREATOR CREATED EDITOR  \\\n",
       "NAME                                                                        \n",
       "Cluster 9   {0D85A9B0-AAE1-4EE0-A311-793BC87ED3C5}    None    None   None   \n",
       "Cluster 31  {84876282-0AFE-4553-8F28-958497FC1A4C}    None    None   None   \n",
       "\n",
       "           EDITED  SHAPE.AREA  SHAPE.LEN  \\\n",
       "NAME                                       \n",
       "Cluster 9    None           0          0   \n",
       "Cluster 31   None           0          0   \n",
       "\n",
       "                                                     geometry  \n",
       "NAME                                                           \n",
       "Cluster 9   POLYGON ((-77.02192 38.88757, -77.02742 38.887...  \n",
       "Cluster 31  POLYGON ((-76.91322 38.88976, -76.91234 38.890...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define path to DC Neighborhood Data\n",
    "dc_path = os.path.join(dc_dir, 'dc-neighborhood.geojson')\n",
    "\n",
    "\n",
    "\n",
    "# If the data does not already exist, save data to directory\n",
    "if not os.path.exists(dc_path):\n",
    "    # Save url for Chicago Neighborhood boundaries\n",
    "    dc_url = (\"https://maps2.dcgis.dc.gov/dcgis/rest/services/DCGIS_DATA/\"\n",
    "            \"Administrative_Other_Boundaries_WebMercator/MapServer/17/\"\n",
    "            \"query?outFields=*&where=1%3D1&f=geojson\"\n",
    "    )\n",
    "    # Save Chicago neighborhood data to a file\n",
    "    gpd.read_file(dc_url).to_file(dc_path)\n",
    "\n",
    "# Create Geodatabase of Chicago Neighborhood Data\n",
    "dc_gdf = gpd.read_file(dc_path).set_index(\"NAME\")\n",
    "\n",
    "# Select Humboldt Park and Lincoln Park Data\n",
    "neigh_gdf = (\n",
    "    dc_gdf\n",
    "    .loc[[\"Cluster 9\", \"Cluster 31\"]]\n",
    ")\n",
    "\n",
    "neigh_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4596c75f3a5704868766ee0db3560337",
     "grade": false,
     "grade_id": "step-3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## STEP 3: Download and process raster data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e2a1f5a358962445e8de4dcb9ed5261",
     "grade": false,
     "grade_id": "task-download",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "You should have three loops from last week. Convert the operations from each loop into a **function**, starting with the following sample code:\n",
    "\n",
    "```python\n",
    "def download_neighborhood_data(name, geometry, start, end)\n",
    "    \"\"\"\n",
    "    Download NAIP raster for a given geometry, start date, and end date\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    name : str\n",
    "      The name used to label the download\n",
    "    geometry : shapely.POLYGON\n",
    "      The geometry to derive the download extent from. \n",
    "      Must have a `.bounds` attribute.\n",
    "    start : str\n",
    "      The start date as 'YYYY-MM-DD'\n",
    "    end : str\n",
    "      The end date as 'YYYY-MM-DD'\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    downloader : earthpy.earthexplorer.EarthExplorerDownloader\n",
    "      Object with information about the download, including the data directory.\n",
    "    \"\"\"\n",
    "    <Put your code here>\n",
    "    return downloader\n",
    "\n",
    "for neighborhood_name, details in neigh_gdf.interrows():\n",
    "    download_neighborhood_data(neighborhood_name, details.geometry)\n",
    "\n",
    "```\n",
    "One important step of writing function is identifying the **Parameters** and **Returns**. In this case, I have done this for you; for later functions you will need to do this yourself. One way to identify the Parameters is to identify each object or variable used in the code (note that this does not usually include imported classes and functions). \n",
    "\n",
    "I am also supplying you with a **docstring** that explains the Parameters and Returns, and specifies their types. Update the docstring if you decide to do something different for your function. When writing docstrings, please follow the [numpy docstring styleguide](https://numpydoc.readthedocs.io/en/latest/format.html#sections)\n",
    "\n",
    "YOUR TASK:\n",
    "\n",
    "1. Replace `<Put your code here>` with the download code from last week\n",
    "2. Open up your summary statistics file, if it exists.\n",
    "3. Add a **conditional** to your code so that it will skip this download if the summary statistics **already exist** in your summary statistics file!\n",
    "   \n",
    "    > HINT: I did this using the `pass` statement, which moves on to the next iteration of the loop. This way you can test if the statistics **do** exist in the file, rather than whether they **do not**. However, there are lots of ways to do this -- do what makes sense to you!\n",
    "    \n",
    "4. Test that the code still works for the two-neighborhood `GeoDataFrame`. You should also check that the caching is working (although you may need to wait until you have saved some statistics to do this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7be14fe3d75462ced1803cf9a1a52cf2",
     "grade": false,
     "grade_id": "ans-download",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in NDVI Statistics File...\n"
     ]
    }
   ],
   "source": [
    "def download_neighborhood_data(name, geometry, start, end):\n",
    "    \"\"\"\n",
    "    Download NAIP raster for a given geometry, start date, and end date\n",
    "\n",
    "    Downloads data from the National Agricultural Imagery Program (NAIP)\n",
    "    given a spatial and temporal extent.\n",
    "    <citation>\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    name : str\n",
    "      The name used to label the download\n",
    "    geometry : shapely.POLYGON\n",
    "      The geometry to derive the download extent from. \n",
    "      Must have a `.bounds` attribute.\n",
    "    start : str\n",
    "      The start date as 'YYYY-MM-DD'\n",
    "    end : str\n",
    "      The end date as 'YYYY-MM-DD'\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    downloader : earthpy.earthexplorer.EarthExplorerDownloader\n",
    "      Object with information about the download, including the data directory.\n",
    "    \"\"\"\n",
    "    print(f'Neighborhood Name: {name}')\n",
    "    # Create bounding box\n",
    "    bbox = etee.BBox(*geometry.bounds)\n",
    "    # Create downloader\n",
    "    naip_downloader = etee.EarthExplorerDownloader(\n",
    "        dataset=\"NAIP\", \n",
    "        label=name.lower().replace(\" \", \"-\"),\n",
    "        bbox=bbox,\n",
    "        start=start,\n",
    "        end=end,\n",
    "        store_credential=True)\n",
    "    # Request and download data\n",
    "    naip_downloader.submit_download_request()\n",
    "    naip_downloader.download(override=False)\n",
    "    return naip_downloader\n",
    "\n",
    "ndvi_stats_path = os.path.join(ndvi_dir, 'neighborhood-ndvi-stats.csv')\n",
    "if os.path.exists(ndvi_stats_path):\n",
    "  print('Reading in NDVI Statistics File...')\n",
    "  ndvi_stats_df = pd.read_csv(ndvi_stats_path, index_col=\"neighborhood\")\n",
    "else:\n",
    "  print('NDVI Statistics File does not exist...')\n",
    "  ndvi_stats_df = pd.DataFrame()\n",
    "\n",
    "# # Run to test\n",
    "# for neighborhood_name, details in neigh_gdf.iterrows():\n",
    "#     if neighborhood_name in ndvi_stats_df.index:\n",
    "#       print(\"Neighborhood stats have already been calculated. Skipping\")\n",
    "#       continue\n",
    "    \n",
    "#     downloader = download_neighborhood_data(\n",
    "#        neighborhood_name, details.geometry, '2021-01-01', '2021-12-31')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "870b3a9b4907656fbc64d5d23e37b538",
     "grade": false,
     "grade_id": "task-load-merge",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "YOUR TASK: \n",
    "\n",
    "1. Write a function for the loop that loads and merges the arrays.\n",
    "2. Document your function with a docstring\n",
    "3. Check that your function works for the Lincoln Park neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92ce6ede0b1456b0cc52aead0b3de308",
     "grade": false,
     "grade_id": "ans-merge",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_and_merge_arrays(name):\n",
    "    \"\"\"\n",
    "    Load in and merge downloaded arrays\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    name : str\n",
    "        The name used to label the download\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    merge_da : rxr.DataArray\n",
    "        Data array with merged data.\n",
    "    \"\"\"\n",
    "    # Merge data for each neighborhood\n",
    "    print(f'\\nNeighborhood Name: {name}')\n",
    "    data_path = os.path.join(\n",
    "        et.io.HOME, et.io.DATA_NAME,\n",
    "        name.lower().replace(' ', '-'))\n",
    "    # Define paths to tif data\n",
    "    tif_paths = glob(os.path.join(data_path, '*.tif'))\n",
    "    # Load tifs\n",
    "    das = [rxr.open_rasterio(tp, masked=True) for tp in tif_paths]\n",
    "    # Merge arrays\n",
    "    merged_da = rxrmerge.merge_arrays(das)\n",
    "    return merged_da\n",
    "\n",
    "# # Run to test\n",
    "# merged_da = load_and_merge_arrays('Cluster 9')\n",
    "# merged_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "705ce678b94060c99feb3967a40ebfb0",
     "grade": false,
     "grade_id": "task-summarize",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "YOUR TASK:\n",
    "\n",
    "1. Write a function that computes the NDVI summary statistics and adds them to the statistics file (if the statistics are not already present)\n",
    "    > HINT: use `mode='a'` to *append* a line to the file instead of writing over existing content\n",
    "    \n",
    "2. Document your function with a docstring\n",
    "3. Check that your function works for the Lincoln Park Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96b502b32233419baede0d41d49b1762",
     "grade": false,
     "grade_id": "ans-ndvi",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Function to compute NDVI summary statistics\n",
    "def calculate_ndvi_stats(gdf, da, stats_path, override=False):\n",
    "    \"\"\"\n",
    "    Calculate NDVI summary statistics and save to statistics file\n",
    "    \n",
    "    Uses downloaded National Agricultural Imagery Program (NAIP) data.\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    gdf : [gpd.GeoDataFrame]\n",
    "        Single row with the neighborhood name and boundary\n",
    "    da : rxr.DataArray\n",
    "        Multispectral raster data from NAIP\n",
    "    stats_path : pathlike\n",
    "        The path to the statistics file to save results\n",
    "    \"\"\"\n",
    "    name = str(gdf.index[0])\n",
    "    print(f'\\nNeighborhood Name: {name}')\n",
    "\n",
    "    file_is_empty = True\n",
    "    if os.path.exists(stats_path):\n",
    "        print('Stats file exists.')\n",
    "        stats_df = pd.read_csv(stats_path)\n",
    "        with open(stats_path, 'r') as stats_file:\n",
    "            file_is_empty = len(stats_file.read())==0\n",
    "            print(f'Stats file is empty? {file_is_empty}')\n",
    "            \n",
    "            if not file_is_empty:\n",
    "                if name in list(stats_df.neighborhood) and (not override):\n",
    "                    print('Stats already calculated. Skipping...')\n",
    "                    return\n",
    "\n",
    "\n",
    "    # Create gdf for neighborhood\n",
    "    reprojected_gdf = gdf.to_crs(da.rio.crs)\n",
    "    # Crop NAIP data array to the neighborhood\n",
    "    naip_crop_da = (\n",
    "        da.rio.clip_box(*reprojected_gdf.total_bounds)\n",
    "        )\n",
    "    naip_da = (\n",
    "        naip_crop_da.rio.clip(reprojected_gdf.geometry)\n",
    "    )\n",
    "    \n",
    "    mode = 'w' if file_is_empty else 'a'\n",
    "    # Calculate NDVI\n",
    "    ndvi_da = (da.sel(band=4) - da.sel(band=1)) / (\n",
    "        da.sel(band=4) + da.sel(band=1)\n",
    "    )\n",
    "    print('Writing stats to file')\n",
    "    file_is_empty = not os.path.exists(stats_path)\n",
    "    # Calculate summary statistics\n",
    "    pd.DataFrame(dict(\n",
    "          neighborhood=[name],\n",
    "          ndvi_25pctl=[np.nanpercentile(ndvi_da, 25)],\n",
    "          ndvi_mean=[float(ndvi_da.mean())]\n",
    "          )).to_csv(stats_path, mode=mode, header=file_is_empty, index=False)\n",
    "\n",
    "# Run to test\n",
    "# calculate_ndvi_stats(dc_gdf.loc[['Lincoln Park']], merged_da, ndvi_stats_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f5cc87a63ce81d58b2c8742cdeab0a6",
     "grade": false,
     "grade_id": "task-loop",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Putting in all together... YOUR TASK:\n",
    "\n",
    "1. Create a loop. Start off with just the two neighborhood `GeoDataFrame`.\n",
    "2. Run each of your functions in the loop, checking that they work. **MAKE SURE YOU INCLUDE CACHING CODE!**\n",
    "3. Write a line of code at the end of your loop to **delete the raster data files** once you have saved the statistics you want, checking that it works. Use the `shutil.rmtree()` function.\n",
    "4. Replace the two neighborhood `GeoDataFrame` with the full Chicago `GeoDataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Cluster 45'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/pth6570.github.io/notebooks/multispectral_analysis.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bjubilant-funicular-jj596r97xr7r35w7g/workspaces/pth6570.github.io/notebooks/multispectral_analysis.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m dc_gdf \u001b[39m=\u001b[39m dc_gdf\u001b[39m.\u001b[39;49mdrop(\u001b[39m'\u001b[39;49m\u001b[39mCluster 45\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bjubilant-funicular-jj596r97xr7r35w7g/workspaces/pth6570.github.io/notebooks/multispectral_analysis.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m dc_gdf\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5196\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   5197\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5198\u001b[0m     labels: IndexLabel \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5206\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5208\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5342\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5343\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5344\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5345\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5346\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5347\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5348\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5349\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5350\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5351\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5352\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4713\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6990\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6991\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6992\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6993\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6994\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Cluster 45'] not found in axis\""
     ]
    }
   ],
   "source": [
    "dc_gdf = dc_gdf.drop('Cluster 45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a65a37500bd48e50dd4207d04090d3d",
     "grade": false,
     "grade_id": "ans-loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood Name: Cluster 3\n",
      "Login Successful.\n",
      "Searching datasets...\n",
      "Using dataset alias: naip\n",
      "Searching scenes...\n",
      "Found 2 scenes\n",
      "2 products found.\n",
      "Downloads staging...\n",
      "/home/jovyan/earth-analytics/data/cluster-3/M_3807708_SE_18_060_20210617.zip\n",
      "Saving download: M_3807708_SE_18_060_20210617\n",
      "/home/jovyan/earth-analytics/data/cluster-3/M_3807708_SE_18_060_20210910.zip\n",
      "Saving download: M_3807708_SE_18_060_20210910\n",
      "\n",
      "Neighborhood Name: Cluster 3\n",
      "\n",
      "Neighborhood Name: Cluster 3\n",
      "Stats file exists.\n",
      "Stats file is empty? False\n",
      "Writing stats to file\n",
      "Neighborhood Name: Cluster 1\n",
      "Login Successful.\n",
      "Searching datasets...\n",
      "Using dataset alias: naip\n",
      "Searching scenes...\n",
      "Found 3 scenes\n",
      "3 products found.\n",
      "Downloads staging...\n",
      "/home/jovyan/earth-analytics/data/cluster-1/M_3807708_SW_18_060_20210910.zip\n",
      "Saving download: M_3807708_SW_18_060_20210910\n",
      "/home/jovyan/earth-analytics/data/cluster-1/M_3807708_SE_18_060_20210617.zip\n",
      "Saving download: M_3807708_SE_18_060_20210617\n",
      "/home/jovyan/earth-analytics/data/cluster-1/M_3807708_SE_18_060_20210910.zip\n",
      "Saving download: M_3807708_SE_18_060_20210910\n",
      "\n",
      "Neighborhood Name: Cluster 1\n",
      "\n",
      "Neighborhood Name: Cluster 1\n",
      "Stats file exists.\n",
      "Stats file is empty? False\n",
      "Writing stats to file\n",
      "Neighborhood Name: Cluster 42\n",
      "Login Successful.\n",
      "Searching datasets...\n",
      "Using dataset alias: naip\n",
      "Searching scenes...\n",
      "Found 4 scenes\n",
      "4 products found.\n",
      "Downloads staging...\n",
      "/home/jovyan/earth-analytics/data/cluster-42/M_3807708_SE_18_060_20210910.zip\n",
      "Saving download: M_3807708_SE_18_060_20210910\n",
      "/home/jovyan/earth-analytics/data/cluster-42/M_3807708_SE_18_060_20210617.zip\n",
      "Saving download: M_3807708_SE_18_060_20210617\n",
      "/home/jovyan/earth-analytics/data/cluster-42/M_3807708_SW_18_060_20210617.zip\n",
      "Saving download: M_3807708_SW_18_060_20210617\n",
      "/home/jovyan/earth-analytics/data/cluster-42/M_3807708_SW_18_060_20210910.zip\n",
      "Saving download: M_3807708_SW_18_060_20210910\n",
      "\n",
      "Neighborhood Name: Cluster 42\n",
      "\n",
      "Neighborhood Name: Cluster 42\n",
      "Stats file exists.\n",
      "Stats file is empty? False\n",
      "Writing stats to file\n",
      "Neighborhood Name: Cluster 6\n",
      "Login Successful.\n",
      "Searching datasets...\n",
      "Using dataset alias: naip\n",
      "Searching scenes...\n",
      "Found 2 scenes\n",
      "2 products found.\n",
      "Downloads staging...\n",
      "/home/jovyan/earth-analytics/data/cluster-6/M_3807708_SE_18_060_20210910.zip\n",
      "Saving download: M_3807708_SE_18_060_20210910\n",
      "/home/jovyan/earth-analytics/data/cluster-6/M_3807708_SE_18_060_20210617.zip\n",
      "Saving download: M_3807708_SE_18_060_20210617\n",
      "\n",
      "Neighborhood Name: Cluster 6\n",
      "\n",
      "Neighborhood Name: Cluster 6\n",
      "Stats file exists.\n",
      "Stats file is empty? False\n",
      "Writing stats to file\n",
      "Neighborhood Name: Cluster 46\n",
      "Login Successful.\n",
      "Searching datasets...\n",
      "Using dataset alias: naip\n",
      "Searching scenes...\n",
      "Found 7 scenes\n",
      "7 products found.\n",
      "Downloads staging...\n",
      "/home/jovyan/earth-analytics/data/cluster-46/M_3807609_NE_18_060_20210617.zip\n",
      "Saving download: M_3807609_NE_18_060_20210617\n",
      "/home/jovyan/earth-analytics/data/cluster-46/M_3807708_SE_18_060_20210617.zip\n",
      "Saving download: M_3807708_SE_18_060_20210617\n",
      "/home/jovyan/earth-analytics/data/cluster-46/M_3807609_NW_18_060_20210617.zip\n",
      "Saving download: M_3807609_NW_18_060_20210617\n",
      "/home/jovyan/earth-analytics/data/cluster-46/M_3807716_NE_18_060_20210910.zip\n",
      "Saving download: M_3807716_NE_18_060_20210910\n",
      "/home/jovyan/earth-analytics/data/cluster-46/M_3807601_SW_18_060_20210617.zip\n",
      "Saving download: M_3807601_SW_18_060_20210617\n",
      "/home/jovyan/earth-analytics/data/cluster-46/M_3807716_NE_18_060_20210617.zip\n",
      "Saving download: M_3807716_NE_18_060_20210617\n",
      "/home/jovyan/earth-analytics/data/cluster-46/M_3807708_SE_18_060_20210910.zip\n",
      "Saving download: M_3807708_SE_18_060_20210910\n",
      "\n",
      "Neighborhood Name: Cluster 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neighborhood Name: Cluster 46\n",
      "Stats file exists.\n",
      "Stats file is empty? False\n",
      "Writing stats to file\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n",
      "Neighborhood stats have already been calculated. Skipping\n"
     ]
    }
   ],
   "source": [
    "# Redefine NDVI stats path\n",
    "ndvi_stats_path = os.path.join(ndvi_dir, 'neighborhood-ndvi-stats.csv')\n",
    "\n",
    "# Loop through all Chicago neighborhoods to download data, merge data,\n",
    "# and calculate NDVI statistics using functions\n",
    "for neighborhood_name, details in dc_gdf.iterrows():\n",
    "    if not os.path.exists(ndvi_stats_path):\n",
    "        print('NDVI statistics file does not exist...')\n",
    "        ndvi_stats_df = pd.DataFrame()\n",
    "    else:\n",
    "        ndvi_stats_df = pd.read_csv(ndvi_stats_path, index_col='neighborhood')\n",
    "        \n",
    "    if neighborhood_name in ndvi_stats_df.index:\n",
    "      print(\"Neighborhood stats have already been calculated. Skipping\")\n",
    "      continue\n",
    "        \n",
    "    downloader = download_neighborhood_data(\n",
    "        neighborhood_name, details.geometry, '2021-01-01', '2021-12-31')\n",
    "    merged_da = load_and_merge_arrays(neighborhood_name)\n",
    "    calculate_ndvi_stats(\n",
    "        dc_gdf.loc[[neighborhood_name]], merged_da, ndvi_stats_path)\n",
    "    \n",
    "    shutil.rmtree(downloader.data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ndvi_summary_stats.csv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndvi_stats_path = os.path.join(ndvi_dir, 'neighborhood-ndvi-stats.csv')\n",
    "\n",
    "shutil.copyfile(ndvi_stats_path, \"ndvi_summary_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2faa5678764519b1c1834cc10c0e8e0",
     "grade": false,
     "grade_id": "cell-d424f92bd00373c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## STEP 4: Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "edb0231452a46a9ed12835cb86480997",
     "grade": false,
     "grade_id": "task-plot",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "YOUR TASK:\n",
    "1. Join your `GeoDataFrame` of Chicago neighborhoods with your NDVI statistics `DataFrame`\n",
    "2. Create a Chloropleth plot using one of the statistics for the color scale\n",
    "3. Write a plot headline and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in NDVI Summary Statistics\n",
    "ndvi_stats_df = pd.read_csv(ndvi_stats_path, index_col=\"neighborhood\")\n",
    "\n",
    "# Create copy of Neighborhood name for use in hover tool\n",
    "joined_dc_df = dc_gdf.join(ndvi_stats_df, how=\"left\")\n",
    "joined_dc_df['name'] = joined_dc_df.index\n",
    "\n",
    "# Define hover tool for Choropleth\n",
    "tooltips = [\n",
    "    ('Neighborhood', '@name'),\n",
    "    ('NDVI', '@ndvi_mean')\n",
    "]\n",
    "hover = HoverTool(tooltips=tooltips)\n",
    "\n",
    "# Create Choropleth of NDVI Statistics\n",
    "choropleth = gv.tile_sources.CartoLight * gv.Polygons(\n",
    "    joined_dc_df,\n",
    "    vdims=['ndvi_mean', 'name']\n",
    ").opts(cmap=\"RdYlGn\",\n",
    "       title=\"NDVI in Chicago Neighborhoods\",\n",
    "       xaxis=None,\n",
    "       yaxis=None,\n",
    "       colorbar=True, \n",
    "       colorbar_position=\"right\",\n",
    "       tools=[hover])\n",
    "\n",
    "# Save Chloropleth to HTML\n",
    "hv.save(choropleth, 'choropleth.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDVI in Chicago Neighborhoods\n",
    "* NDVI tends to be lower closer to the lake. \n",
    "* Areas further from the lake tend to have higher NDVI.\n",
    "* In general, NDVI tends to be low (under zero) in Chicago."
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "249.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
